{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S3E3_A2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfVgDy3A3WIY",
        "colab_type": "text"
      },
      "source": [
        "#Learnings\n",
        "\n",
        "Code source: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGfALP0Z4Yt9",
        "colab_type": "text"
      },
      "source": [
        "###import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9rJ3x2_3Xms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpEbyebt4dU1",
        "colab_type": "text"
      },
      "source": [
        "### Connecting to google drive\n",
        "Used for load .txt file from the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_NquEHI3YXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2de7aefa-e872-46d4-dab2-40794ccdb812"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 24.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 3.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5kSQvky4x90",
        "colab_type": "text"
      },
      "source": [
        "### Small LSTM Network to Generate Text for Alice in Wonderland"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBYTW8eN456X",
        "colab_type": "text"
      },
      "source": [
        "Load necessary libs and load the text file from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7vaTUCC3qHg",
        "colab_type": "code",
        "outputId": "88d8d0d6-71f0-41bf-a955-66a330a1d0be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "import os\n",
        "\n",
        "#https://mc.ai/how-to-save-and-upload-deep-learning-machine-learning-models-in-google-colab-using-google-drive/\n",
        "downloaded = drive.CreateFile({'id':'1rReMgfp_-1gP7BgGN6923Gea5c0QgIzq'}) #https://drive.google.com/open?id=1rReMgfp_-1gP7BgGN6923Gea5c0QgIzq # NOTE: id is from sharable link\n",
        "filename = \"Wonderland1.txt\" #/content/drive/My Drive/\n",
        "downloaded.GetContentFile(filename)\n",
        "raw_text = open(filename).read()\n",
        "\n",
        "# load ascii text and covert to lowercase\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 21:25:00.376646 140388265539456 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoI1GOiY5rcZ",
        "colab_type": "text"
      },
      "source": [
        "###Display few character of the raw text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpbhPuIF5peK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "70f620f4-4b42-4bf1-caab-96f08d66b4d0"
      },
      "source": [
        "first_50_letters = raw_text[:50]\n",
        "print(first_50_letters)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿alice's adventures in wonderland\n",
            "\n",
            "chapter i. down\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45VyjFLS5qaH",
        "colab_type": "text"
      },
      "source": [
        "###Remove punctuations from the raw text\n",
        "###Display first 50 characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqeI63TDKBKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "269cec2a-7587-43d1-9558-3b08e54b39db"
      },
      "source": [
        "import string\n",
        "punctuations = set(string.punctuation)\n",
        "raw_text = ''.join(ch for ch in raw_text if ch not in punctuations)\n",
        "first_50_letters = raw_text[:50]\n",
        "print(first_50_letters)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿alices adventures in wonderland\n",
            "\n",
            "chapter i down t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqBHF8X-LRNU",
        "colab_type": "text"
      },
      "source": [
        "###Convert char to int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOC9DB1WKXOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1e19c6f2-483a-471d-dcdc-a66b2ea9b1b5"
      },
      "source": [
        "#create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  \n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  136037\n",
            "Total Vocab:  29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2YZMwpyLcqD",
        "colab_type": "text"
      },
      "source": [
        "### pad_sequences with post padding is used \n",
        "https://machinelearningmastery.com/data-preparation-variable-length-input-sequences-sequence-prediction/\n",
        "\n",
        "helps in forming equal length data, padding value is zero not a random value\n",
        "(Train the model on padded sentences rather than random sequences of characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCdq4-AHLc-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "dataX = pad_sequences(dataX, padding='post', maxlen=100)\n",
        "n_patterns = len(dataX)\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITyd1fUjNU0g",
        "colab_type": "text"
      },
      "source": [
        "### Constructing LSTM model\n",
        "https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/\n",
        "LSTM can be regularized by dropping different sequences(time steps) as follows:\n",
        "  \n",
        "    1. input sequence,   -> dropout used within LSTM layer\n",
        "    2. recurrent input (h or feedback sequence),-> recurrent_dropout used within LSTM layer\n",
        "    3. output sequence (which will be fed to proceeding layer) -> dropout used after LSTM layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y3UGfXhNIJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), dropout=0.1,return_sequences=True))# assignment add dropout of 0.1 to input layer\n",
        "model.add(Dropout(0.1))# assignment dropout = 0.1\n",
        "model.add(LSTM(256))\n",
        "# model.add(Dropout(0.2)) # assignment remove dropout\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6VqHMxVQw3h",
        "colab_type": "text"
      },
      "source": [
        "###Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeTtZTL5QrHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "fe92f66d-cb82-4ba4-8788-23cab638929a"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=10, batch_size=64)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 13:37:15.901035 139930500745088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 13:37:15.929053 139930500745088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0726 13:37:16.057057 139930500745088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "135937/135937 [==============================] - 557s 4ms/step - loss: 2.6353\n",
            "Epoch 2/10\n",
            "135937/135937 [==============================] - 544s 4ms/step - loss: 2.2184\n",
            "Epoch 3/10\n",
            "135937/135937 [==============================] - 545s 4ms/step - loss: 2.0162\n",
            "Epoch 4/10\n",
            "135937/135937 [==============================] - 544s 4ms/step - loss: 1.8761\n",
            "Epoch 5/10\n",
            "135937/135937 [==============================] - 553s 4ms/step - loss: 1.7738\n",
            "Epoch 6/10\n",
            "135937/135937 [==============================] - 543s 4ms/step - loss: 1.6911\n",
            "Epoch 7/10\n",
            "135937/135937 [==============================] - 543s 4ms/step - loss: 1.6263\n",
            "Epoch 8/10\n",
            "135937/135937 [==============================] - 549s 4ms/step - loss: 1.5645\n",
            "Epoch 9/10\n",
            "135937/135937 [==============================] - 549s 4ms/step - loss: 1.5118\n",
            "Epoch 10/10\n",
            "135937/135937 [==============================] - 558s 4ms/step - loss: 1.4613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43d0e66eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAcLYzH4Q3GX",
        "colab_type": "text"
      },
      "source": [
        "### Saved the model in local drive for every 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ios_bJlFQ1ur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "25d98680-1b07-4e91-950e-0914ab14825c"
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save(\"LSTM_model_1.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 15:24:42.353788 140090655033216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q4PQ3pN37UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0mg6iMDRHPZ",
        "colab_type": "text"
      },
      "source": [
        "### Upload the model from local drive to colab "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCs0S4gARPCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2nd 5 epochs  => 10+5 = 15\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZEOkUScRr3-",
        "colab_type": "text"
      },
      "source": [
        "### load the model -> compile-> fit ->save -> download to local drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrFG098XRrE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cb0d58e5-2302-488c-ef23-fb05f9c54ce7"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_2 = load_model(\"LSTM_model_1.h5\")\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_2.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "model_2.save(\"LSTM_model_2.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 562s 4ms/step - loss: 2.6750\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 581s 4ms/step - loss: 2.2643\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 580s 4ms/step - loss: 2.0548\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 578s 4ms/step - loss: 1.9073\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 587s 4ms/step - loss: 1.8086\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OInaO5yuSTJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4tPPdZX2RMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3rd 5 epochs  => 15+5 = 20\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LSBg9M22mQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ccb844c5-1e0e-4e08-e231-672278dfc1cd"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_3 = load_model(\"LSTM_model_2.h5\")\n",
        "model_3.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_3.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "model_3.save(\"LSTM_model_3.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 583s 4ms/step - loss: 1.7260\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 576s 4ms/step - loss: 1.6601\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 575s 4ms/step - loss: 1.6036\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 575s 4ms/step - loss: 1.5537\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 569s 4ms/step - loss: 1.5494\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0meFbf0Pvppw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnlXWcjhedNV",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "15b434a2-4e14-4f30-fdcb-2d74aad97116"
      },
      "source": [
        "#4th 5 epochs  => 20+5 = 25\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2fda692-3438-49d8-9dd5-e1faa2a77bdc\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b2fda692-3438-49d8-9dd5-e1faa2a77bdc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving LSTM_model_3.h5 to LSTM_model_3.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9x3wlJ3edbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "01914621-1e2e-482e-ee2c-c8590e2ed437"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_4 = load_model(\"LSTM_model_3.h5\")\n",
        "model_4.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_4.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "model_4.save(\"LSTM_model_4.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 600s 4ms/step - loss: 1.5003\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 592s 4ms/step - loss: 1.4397\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 591s 4ms/step - loss: 1.3959\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 586s 4ms/step - loss: 1.3576\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 583s 4ms/step - loss: 1.3258\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yJX1GHledr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_4.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ajpIG4luwK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#5th 5 epochs  => 25+5 = 30\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_C9lFrEuwXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1e10e165-2941-4c6a-e50d-7285c7a72b58"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_5 = load_model(\"LSTM_model_4.h5\")\n",
        "model_5.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_5.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "model_5.save(\"LSTM_model_5.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 600s 4ms/step - loss: 1.2941\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 602s 4ms/step - loss: 1.2624\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 588s 4ms/step - loss: 1.2330\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 593s 4ms/step - loss: 1.2097\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 598s 4ms/step - loss: 1.2507\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60BHrYiQuwjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_5.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTUT6JOPb24d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#6th 5 epochs  => 30+5 = 35\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf0QADurb_Q_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "3eef76b9-075d-4d77-879c-3ab13ea6067a"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_6 = load_model(\"LSTM_model_5.h5\")\n",
        "model_6.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_6.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "model_6.save(\"LSTM_model_6.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 605s 4ms/step - loss: 1.2796\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 604s 4ms/step - loss: 1.2481\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 591s 4ms/step - loss: 1.2281\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 587s 4ms/step - loss: 1.2025\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 590s 4ms/step - loss: 1.1818\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oxebD0t59iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_6.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGSEYEzioIqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#7th 5 epochs  => 35+5 = 40\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ORPu4lJolrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "fbd2d762-51aa-4d3a-fba1-7d82a6ab930b"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_7 = load_model(\"LSTM_model_6.h5\")\n",
        "model_7.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_7.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "model_7.save(\"LSTM_model_7.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 583s 4ms/step - loss: 1.1643\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 583s 4ms/step - loss: 1.1438\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 590s 4ms/step - loss: 1.1302\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 578s 4ms/step - loss: 1.1220\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 567s 4ms/step - loss: 1.1187\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkNtpuUSol3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_7.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_71cbuXJo8rL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#8th 5 epochs  => 40+5 = 45\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6eA4v_-6xCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "959f38bb-0921-443b-d714-dd7ddf0c6eee"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_8 = load_model(\"LSTM_model_7.h5\")\n",
        "model_8.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_8.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "model_8.save(\"LSTM_model_8.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 581s 4ms/step - loss: 1.0984\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 567s 4ms/step - loss: 1.0867\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 561s 4ms/step - loss: 1.0756\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 558s 4ms/step - loss: 1.0684\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 560s 4ms/step - loss: 1.0559\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAOr8YQHS09a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_8.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm9gllZbHboc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#9th 5 epochs  => 45+5 = 50\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJQOgrfCSotD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "644c4c8b-7101-4311-8e02-73b08842e65e"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_9 = load_model(\"LSTM_model_8.h5\")\n",
        "model_9.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_9.fit(X, y, epochs=5, batch_size=64)\n",
        "\n",
        "model_9.save(\"LSTM_model_9.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 571s 4ms/step - loss: 1.0489\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 564s 4ms/step - loss: 1.0390\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 562s 4ms/step - loss: 1.0325\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 565s 4ms/step - loss: 1.0240\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 563s 4ms/step - loss: 1.0169\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3eS-pzWStze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_9.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1wFaAb9TTxy",
        "colab_type": "text"
      },
      "source": [
        "As the train is slow, and in loss difference is less between epochs\n",
        "lets try to use learning rate in adam for fast learning-- loss increased drastically\n",
        "\n",
        "Increase batch  size for fast learning\n",
        "But authour told to keep as minimum as possible.\n",
        "lets see what happens\n",
        "\n",
        "Loss reducing - fast training eta of 6mins  previous batchsize =64 eta was 9.5mins ----> observation: good to go with increasing batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKzQmjulTOJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#10th 5 epochs  => 50+5 = 55\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmUxFSW3TOWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "5e97a25c-7f9d-487d-c0d9-f5e77ad5ba65"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "model_10 = load_model(\"LSTM_model_9.h5\")\n",
        "\n",
        "#adam1 = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model_10.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_10.fit(X, y, epochs=5, batch_size=100)\n",
        "\n",
        "model_10.save(\"LSTM_model_10.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 389s 3ms/step - loss: 0.9720\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 389s 3ms/step - loss: 0.9495\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 390s 3ms/step - loss: 0.9336\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 389s 3ms/step - loss: 0.9277\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 385s 3ms/step - loss: 0.9180\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grbj1i_YTOi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_10.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMOpMBLrmltG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#11th 5 epochs  => 55+5 = 60\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjXnY1hSmpFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "97310ad3-d4dc-4719-996e-ded48ee50a14"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "model_11 = load_model(\"LSTM_model_10.h5\")\n",
        "\n",
        "#adam1 = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model_11.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_11.fit(X, y, epochs=5, batch_size=100)\n",
        "\n",
        "model_11.save(\"LSTM_model_11.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 397s 3ms/step - loss: 0.9152\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 391s 3ms/step - loss: 0.9056\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 391s 3ms/step - loss: 0.8961\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 383s 3ms/step - loss: 0.8947\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 379s 3ms/step - loss: 0.8864\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_6OIZtzm3Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_11.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shgaXQunyb7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#12th 5 epochs  => 60+5 = 65\n",
        "\n",
        "from google.colab import files\n",
        "model_new = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0BMR0o4yfXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f5a1d074-2ad6-42a6-a949-fc24b18a4411"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "model_12 = load_model(\"LSTM_model_11.h5\")\n",
        "\n",
        "#adam1 = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model_12.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# fit the model\n",
        "model_12.fit(X, y, epochs=5, batch_size=200)\n",
        "\n",
        "model_12.save(\"LSTM_model_12.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "135937/135937 [==============================] - 208s 2ms/step - loss: 0.8335\n",
            "Epoch 2/5\n",
            "135937/135937 [==============================] - 201s 1ms/step - loss: 0.8095\n",
            "Epoch 3/5\n",
            "135937/135937 [==============================] - 196s 1ms/step - loss: 0.7977\n",
            "Epoch 4/5\n",
            "135937/135937 [==============================] - 200s 1ms/step - loss: 0.7856\n",
            "Epoch 5/5\n",
            "135937/135937 [==============================] - 198s 1ms/step - loss: 0.7805\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4386kYVyvlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('LSTM_model_12.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKiLO3IqA6b0",
        "colab_type": "text"
      },
      "source": [
        "#### pattern.append(index) : not working hence using np.append"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RSZrnie80vQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "132e67de-8de5-42fd-cc6d-877ffb831a38"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)+1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = (x / float(n_vocab))\n",
        "    prediction = model_12.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern = np.append(pattern,index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" proved it at all however she went on and how\n",
            "do you know that youre mad\n",
            "\n",
            "to begin with said the cat  \"\n",
            "i hive ieard a little betides sr converslog in the walk asg all torrise\n",
            "\n",
            "whe fuog of thoined the had nookingny done what she wale uuch a thiht seroled turping tuuprised thesh yould be ourerf the fver setfaked hew mnnw the walted a little bnteadid the waid tuceen and where where suoeiers thall ever hetting tumed hereranly have anl have anyays good ou narehned tolebody else the had slease sarty suick and temovel taid to the\n",
            "whoug and the hot keading ano ano tour\n",
            "\n",
            "the waited po the fru out heart horesatissed out what she wale tuceeng\n",
            "inp tuay tuch a nittle whryg antws hor hat byt when whe qtpccsume wioles hot have yonder as ie b gaw what ie soease serpled ovt hetting anl tound het\n",
            "monw the walted a little bnteadid the waid tound anice\n",
            "\n",
            "anice suoted intor\n",
            "the wale tuokshe\n",
            "\n",
            "alice whought the havter way only twitting how iardent have yonder at sueer soanle anice hestelf and whe grogfnth said in anyt a littoe\n",
            "\n",
            "iip arp pow the satte ierpely sroernf\n",
            "ttutisg\n",
            "the helt a long and wheres note befor\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfkFyHH0BQVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}